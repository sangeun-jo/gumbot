import os
import pandas as pd
import numpy as np
from numpy import dot
from numpy.linalg import norm 
import ast 
import openai
import streamlit as st
from streamlit_chat import message
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Streamlit í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="êµ¼ë´‡", page_icon="ğŸ¤–")

# API í‚¤ ì„¤ì • ë°©ì‹ ê°œì„ 
api_key = None
# 1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ í‚¤ í™•ì¸
if os.getenv("OPENAI_API_KEY"):
    api_key = os.getenv("OPENAI_API_KEY")
# 2. Streamlit ì‹œí¬ë¦¿ì—ì„œ í‚¤ í™•ì¸
elif "OPENAI_KEY" in st.secrets:
    api_key = st.secrets["OPENAI_KEY"]

# API í‚¤ ìœ íš¨ì„± ê²€ì‚¬ ë° ì„¤ì •
if not api_key:
    st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    st.info("í•´ê²° ë°©ë²•: Streamlit Cloudì—ì„œëŠ” 'OPENAI_KEY'ë¥¼ ì‹œí¬ë¦¿ì— ì„¤ì •í•˜ì„¸ìš”. ë¡œì»¬ì—ì„œëŠ” .env íŒŒì¼ì— 'OPENAI_API_KEY'ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")
    st.stop()

# API í‚¤ ì„¤ì •    
openai.api_key = api_key

def get_embedding(text):
    try:
        response = openai.Embedding.create(
            model="text-embedding-ada-002",
            input=text
        )
        return response['data'][0]['embedding']
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

folder_path = "./data"
file_name = 'embeddings.csv'
file_path = os.path.join(folder_path, file_name)

# ë°ì´í„° ë¡œë”© ë¶€ë¶„
try:
    print("======íŒŒì¼ ê²½ë¡œ=======")
    print(file_path)
    
    # ì„ë² ë”© íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° ë¶ˆëŸ¬ì˜¤ê¸°
    if os.path.isfile(file_path):
        print("File already exists")
        df = pd.read_csv(file_path)
        df['embedding'] = df['embedding'].apply(ast.literal_eval)
    else:
        # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°ë§Œ ì„ë² ë”© ìƒì„±
        st.info("ì„ë² ë”© íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        
        # ë°ì´í„° í´ë” í™•ì¸
        if not os.path.exists(folder_path):
            st.error(f"ë°ì´í„° í´ë”({folder_path})ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            st.stop()
            
        txt_file = [file for file in os.listdir(folder_path) if file.endswith('.txt')]
        if not txt_file:
            st.error(f"ë°ì´í„° í´ë”({folder_path})ì— .txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        print("======txt íŒŒì¼ ëª©ë¡ =======")
        print(txt_file)
        data = []
        for file in txt_file:
            txt_file_path = os.path.join(folder_path, file)
            with open(txt_file_path, 'r', encoding='utf-8') as f:
                text = f.read()
                data.append(text)
        
        df = pd.DataFrame(data, columns=['text'])
        df['embedding'] = df.apply(lambda row: get_embedding(row.text), axis=1)
        
        # None ê°’ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì œê±°
        if df['embedding'].isna().any():
            st.error("ì¼ë¶€ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            st.stop()
            
        df.to_csv(file_path, index=False, encoding='utf-8-sig')
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
    st.stop()

def cos_sim(A, B):
    return dot(A, B) / (norm(A) * norm(B))

def return_answer_candidate(df, query):
    query_embedding = get_embedding(query)
    if query_embedding is None:
        st.error("ì§ˆë¬¸ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        st.stop()
        
    df["similarity"] = df.embedding.apply(lambda x: cos_sim(np.array(x), np.array(query_embedding)))
    top_three_doc = df.sort_values("similarity", ascending=False).head(3)

    return top_three_doc

def create_prompt(df, query):
    print("======í”„ë¡¬í”„íŠ¸ ìƒì„±=======")
    result = return_answer_candidate(df, query)
    system_role = f"""Your are an aritifical intelligence language model named "êµ¼ë´‡" that specializes in summarizing \
    and answering questions about "êµ¼ë²µì´", developed by developers ì¡°ìƒì€.
    You need to take a given document and return a very detailed summary of the document in the query language.
    Here are the document:
        doc 1: """ + str(result.iloc[0]['text']) + """
        doc 2: """ + str(result.iloc[1]['text']) + """
        doc 3: """ + str(result.iloc[2]['text']) + """
    You must return in Korean. Return a accurate answer based on the document. 
    """

    user_content = f"""User question: "{str(query)}"."""

    messages = [
        {"role": "system", "content": system_role},
        {"role": "user", "content": user_content}
    ]
    print(messages)
    return messages 

def generate_answer(messages):
    try:
        result = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.4,
            max_tokens=500
        )
        return result.choices[0].message.content
    except Exception as e:
        st.error(f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ê±°ë‚˜ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

print("======ì´ë¯¸ì§€ ë³´ì—¬ì£¼ê¸°=======")
# ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
try:
    st.image('images/ask_me_chatbot.png')
except Exception as e:
    st.warning("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì±—ë´‡ì€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")

if 'generated' not in st.session_state:
    st.session_state['generated'] = []

if 'past' not in st.session_state:
    st.session_state['past'] = []

with st.form('form', clear_on_submit=True):
    user_input = st.text_input('êµ¼ë²µì´ì— ëŒ€í•´ ë¬¼ì–´ë³´ì„¸ìš”!: ', key='input')
    submitted = st.form_submit_button('ì „ì†¡')


if submitted and user_input:
    try:
        prompt = create_prompt(df, user_input)
        print("======í”„ë¡¬í”„íŠ¸ ìƒì„±=======")
        print(prompt)
        chatbot_response = generate_answer(prompt)
        st.session_state['past'].append(user_input)
        st.session_state['generated'].append(chatbot_response)
    except Exception as e:
        st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

if st.session_state['generated']:
    for i in reversed(range(len(st.session_state['generated']))):
        message(st.session_state['past'][i], is_user=True, key=str(i) + '_user')
        message(st.session_state['generated'][i], key=str(i))

# í´ë” ë° API í‚¤ ì„¤ì • ë°©ë²• ì•ˆë‚´
with st.sidebar:
    st.subheader("ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    ### ë°ì´í„° í´ë” ì„¤ì •
    - `./data` í´ë”ì— í…ìŠ¤íŠ¸ íŒŒì¼(`.txt`)ì„ ë„£ìœ¼ì„¸ìš”.
    - ì²˜ìŒ ì‹¤í–‰ ì‹œ ì„ë² ë”©ì´ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
    
    ### API í‚¤ ì„¤ì •
    - ë¡œì»¬ ì‹¤í–‰: `.env` íŒŒì¼ì— `OPENAI_API_KEY=your_key_here` ì¶”ê°€
    - Streamlit Cloud: ì‹œí¬ë¦¿ì— `OPENAI_KEY` ì¶”ê°€
    """)


